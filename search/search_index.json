{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ALchemist","text":"<p>ALchemist: Active Learning Toolkit for Chemical and Materials Research</p> <p>ALchemist is a modular Python toolkit that brings active learning and Bayesian optimization to experimental design in chemical and materials research. It is designed for scientists and engineers who want to efficiently explore or optimize high-dimensional variable spaces\u2014without writing code\u2014using an intuitive graphical interface.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Flexible variable space definition: Real, integer, and categorical variables with bounds or discrete values.</li> <li>Probabilistic surrogate modeling: Gaussian process regression via BoTorch or scikit-optimize backends.</li> <li>Advanced acquisition strategies: Efficient sampling using qEI, qPI, qUCB, and qNegIntegratedPosteriorVariance.</li> <li>Intuitive GUI workflow: No coding required\u2014define variables, generate initial experiments, load data, train models, and suggest new experiments.</li> <li>Experiment tracking: CSV logging, reproducible random seeds, and error tracking.</li> <li>Extensibility: Abstract interfaces for models and acquisition functions enable future backend and workflow expansion.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>We recommend using Anaconda to manage your Python environments for ALchemist.</p> <p>1. Create a new environment: <pre><code>conda create -n alchemist-env python=3.12\nconda activate alchemist-env\n</code></pre></p> <p>2. Clone the ALchemist repository: <pre><code>git clone https://github.com/calebcoatney/ALchemist.git\ncd ALchemist\n</code></pre></p> <p>3. Install ALchemist: <pre><code>python -m pip install -e .\n</code></pre></p> <p>All dependencies are specified in <code>pyproject.toml</code> and will be installed automatically.</p> <p>After installation, launch the graphical user interface by running:</p> <pre><code>alchemist\n</code></pre> <p>Use the sidebar to navigate through the documentation. See Getting Started to define your variable space and generate initial experiments.</p>"},{"location":"acquisition/botorch/","title":"BoTorch Acquisition Functions","text":"<p>The BoTorch backend in ALchemist provides a flexible and powerful interface for selecting the next experiment(s) using a variety of acquisition functions from the BoTorch library. This guide explains the available options, how to use them, and what each setting means.</p>"},{"location":"acquisition/botorch/#overview","title":"Overview","text":"<p>The Acquisition panel in ALchemist allows you to:</p> <ul> <li>Choose between Regular, Batch, and Exploratory acquisition strategies.</li> <li>Select from several acquisition functions, each balancing exploration and exploitation in different ways.</li> <li>Customize parameters such as batch size and Monte Carlo integration points.</li> <li>Run the selected strategy to suggest the next experiment(s) based on your trained model.</li> </ul>"},{"location":"acquisition/botorch/#important-note","title":"Important Note","text":"<p>You must first train your model using the BoTorch backend before running any BoTorch acquisition functions. See BoTorch Backend for details on model training.</p>"},{"location":"acquisition/botorch/#acquisition-types","title":"Acquisition Types","text":""},{"location":"acquisition/botorch/#1-regular-acquisition","title":"1. Regular Acquisition","text":"<ul> <li>Expected Improvement (EI):   Suggests points with the highest expected improvement over the current best observed value.</li> <li>Log Expected Improvement (LogEI):   Numerically stable version of EI.</li> <li>Probability of Improvement (PI):   Selects points with the highest probability of improving over the current best value.</li> <li>Log Probability of Improvement (LogPI):   Numerically stable version of PI.</li> <li>Upper Confidence Bound (UCB):   Balances exploration and exploitation by selecting points with the highest upper confidence bound.</li> </ul> <p>Customization: - Choose to maximize or minimize your objective.</p>"},{"location":"acquisition/botorch/#2-batch-acquisition","title":"2. Batch Acquisition","text":"<ul> <li>q-Expected Improvement (qEI):   Selects a batch of points that together maximize expected improvement.</li> <li>q-Upper Confidence Bound (qUCB):   Batch version of UCB.</li> </ul> <p>Customization: - Set batch size (number of points to suggest at once, q). - Monte Carlo samples (mc_samples) are used internally for batch methods.</p>"},{"location":"acquisition/botorch/#3-exploratory-acquisition","title":"3. Exploratory Acquisition","text":"<ul> <li>Integrated Posterior Variance (qNIPV):   Selects points to reduce overall model uncertainty, focusing on exploration rather than optimization.</li> </ul> <p>Customization: - Set the number of Monte Carlo integration points (higher values improve accuracy but increase computation time; 500\u20132000 is typical).</p>"},{"location":"acquisition/botorch/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Train Model:    Train your model using the BoTorch backend. See BoTorch Backend for instructions.</p> </li> <li> <p>Open Acquisition Panel:    Go to the Acquisition panel. The BoTorch options will appear automatically.</p> </li> <li> <p>Choose Acquisition Type:    Use the segmented button to select Regular, Batch, or Exploratory.</p> </li> <li> <p>Configure Options: </p> </li> <li>Select the acquisition function from the dropdown.</li> <li>Adjust parameters (batch size, MC points) as needed.</li> <li> <p>Choose whether to maximize or minimize.</p> </li> <li> <p>Run Acquisition:    Click Run Acquisition Strategy to suggest the next experiment(s). Results, including predicted value and uncertainty, will be shown in a notification window and highlighted in the data table and plots.</p> </li> </ol>"},{"location":"acquisition/botorch/#model-optimum-finder","title":"Model Optimum Finder","text":"<p>In addition to acquisition functions, you can use the Model Prediction Optimum tool to find the point where the model predicts the best value (maximum or minimum). Note: This does not balance exploration and exploitation\u2014it simply finds the model's optimum prediction.</p>"},{"location":"acquisition/botorch/#tips-notes","title":"Tips &amp; Notes","text":"<ul> <li>Batch Acquisition: Use batch mode to suggest multiple experiments at once, useful for parallel experimentation.</li> <li>Exploratory Mode: Use qNIPV when you want to reduce model uncertainty rather than optimize the objective.</li> <li>Parameter Tuning: Increase MC points for more accurate but slower exploratory acquisition.</li> <li>Publication Quality: All results and suggested points are integrated with ALchemist's visualization tools for easy analysis and export.</li> </ul> <p>For more details on the underlying algorithms, see the BoTorch documentation</p>"},{"location":"acquisition/logging/","title":"Logging &amp; Tracking","text":"<p>ALchemist provides robust logging and notification features to help you keep track of your optimization workflow, model settings, and acquisition strategies. This is essential for reproducibility, transparency, and effective reporting in scientific research.</p>"},{"location":"acquisition/logging/#notifications-immediate-feedback-for-each-acquisition","title":"Notifications: Immediate Feedback for Each Acquisition","text":"<p>Whenever you execute an acquisition strategy (e.g., suggest the next experiment), a notification window will automatically pop up. This window provides a detailed summary of the result, including:</p> <ul> <li> <p>Point Details:   The coordinates of the suggested next experiment (or batch of experiments), along with predicted values, uncertainties, and 95% confidence intervals.</p> </li> <li> <p>Model Info:   Information about the trained model, including backend (BoTorch or scikit-optimize), kernel type, learned hyperparameters, and recent performance metrics (e.g., RMSE, R\u00b2).</p> </li> <li> <p>Strategy Info:   Details about the acquisition strategy used, including the type (e.g., Expected Improvement, qEI), optimization goal (maximize/minimize), and any relevant parameters.</p> </li> <li> <p>Export Options:   You can export all of this information to a CSV file for record-keeping, publication, or further analysis.</p> </li> </ul> <p>This notification system ensures you always have a clear record of what was suggested and why.</p>"},{"location":"acquisition/logging/#logging-keeping-a-complete-experiment-record","title":"Logging: Keeping a Complete Experiment Record","text":"<p>ALchemist includes an experiment logger that tracks every key step in your workflow:</p> <ul> <li> <p>Model Training:   Logs backend, kernel, hyperparameters, and performance metrics each time you train or update your model.</p> </li> <li> <p>Acquisition Strategies:   Logs the details of every acquisition function execution, including the strategy, parameters, suggested points, predicted values, and uncertainties.</p> </li> <li> <p>Experiment Data:   Logs the current state of your experimental dataset, including variable names and summary statistics.</p> </li> <li> <p>Exported Logs:   All logs are saved in timestamped files in the <code>logs/</code> directory, making it easy to revisit or share your workflow history.</p> </li> </ul>"},{"location":"acquisition/logging/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Log Every Iteration:   After each acquisition and model update, use the export and logging features to save your results. This ensures you can always trace back which model, kernel, and acquisition strategy led to each experimental suggestion.</p> </li> <li> <p>Reproducibility:   Keeping detailed logs allows you (and others) to reproduce your optimization process, which is essential for scientific rigor and publication.</p> </li> <li> <p>Transparency:   By exporting notifications and logs, you can clearly communicate your workflow, decisions, and results to collaborators, reviewers, or future users.</p> </li> </ul>"},{"location":"acquisition/logging/#summary","title":"Summary","text":"<p>ALchemist\u2019s notification and logging system is designed to make your active learning workflow transparent, reproducible, and easy to document. Make it a habit to export and log your results at each step\u2014this will pay dividends when you need to report, troubleshoot, or publish your work.</p>"},{"location":"acquisition/skopt/","title":"scikit-optimize Acquisition Functions","text":"<p>The scikit-optimize (skopt) backend in ALchemist provides a range of acquisition functions for Bayesian optimization using the scikit-optimize library. This guide explains the available options, how to use them, and what each setting means.</p>"},{"location":"acquisition/skopt/#overview","title":"Overview","text":"<p>The Acquisition panel in ALchemist allows you to:</p> <ul> <li>Choose from several acquisition functions, each balancing exploration and exploitation in different ways.</li> <li>Customize parameters such as exploration/exploitation trade-offs.</li> <li>Run the selected strategy to suggest the next experiment based on your trained model.</li> </ul>"},{"location":"acquisition/skopt/#important-note","title":"Important Note","text":"<p>You must first train your model using the scikit-optimize backend before running any skopt acquisition functions. See scikit-optimize Backend for details on model training.</p>"},{"location":"acquisition/skopt/#acquisition-functions","title":"Acquisition Functions","text":"<ul> <li> <p>Expected Improvement (EI):   Balances exploration and exploitation by selecting points with the highest expected improvement over the current best value. Parameter: \u03be (xi) \u2014 higher values favor exploration.</p> </li> <li> <p>Upper Confidence Bound (UCB):   Selects points with the highest upper confidence bound, balancing exploration and exploitation. Parameter: \u03ba (kappa) \u2014 higher values increase exploration.</p> </li> <li> <p>Probability of Improvement (PI):   Selects points with the highest probability of improving over the current best value. Parameter: \u03be (xi) \u2014 higher values favor exploration.</p> </li> <li> <p>GP Hedge (Auto-balance):   Automatically balances between EI, UCB, and PI by adaptively selecting the best-performing strategy during optimization. Parameters: \u03be (xi) and \u03ba (kappa).</p> </li> </ul> <p>Customization: - Choose to maximize or minimize your objective. - Adjust \u03be (xi) and \u03ba (kappa) parameters using sliders as appropriate for the selected acquisition function.</p>"},{"location":"acquisition/skopt/#how-to-use","title":"How to Use","text":"<ol> <li> <p>Train Model:    Train your model using the scikit-optimize backend. See scikit-optimize Backend for instructions.</p> </li> <li> <p>Open Acquisition Panel:    Go to the Acquisition panel. The scikit-optimize options will appear automatically.</p> </li> <li> <p>Select Acquisition Function:    Use the dropdown menu to select the acquisition function (EI, UCB, PI, or GP Hedge).</p> </li> <li> <p>Configure Options: </p> </li> <li>Adjust \u03be (xi) and \u03ba (kappa) parameters as needed.</li> <li> <p>Choose whether to maximize or minimize.</p> </li> <li> <p>Run Acquisition:    Click Run Acquisition Strategy to suggest the next experiment. Results, including predicted value and uncertainty, will be shown in a notification window and highlighted in the data table and plots.</p> </li> </ol>"},{"location":"acquisition/skopt/#model-optimum-finder","title":"Model Optimum Finder","text":"<p>In addition to acquisition functions, you can use the Model Prediction Optimum tool to find the point where the model predicts the best value (maximum or minimum). Note: This does not balance exploration and exploitation\u2014it simply finds the model's optimum prediction.</p>"},{"location":"acquisition/skopt/#tips-notes","title":"Tips &amp; Notes","text":"<ul> <li>Parameter Tuning: </li> <li>Increase \u03be (xi) or \u03ba (kappa) for more exploration; decrease for more exploitation.</li> <li>GP Hedge is useful if you are unsure which acquisition function to use.</li> <li>Publication Quality:   All results and suggested points are integrated with ALchemist's visualization tools for easy analysis and export.</li> </ul> <p>For more details on the underlying algorithms,</p>"},{"location":"background/bayesian_optimization/","title":"Introduction to Bayesian Optimization","text":"<p>Bayesian Optimization (BO) is a method for efficiently optimizing complex systems, particularly when experiments or evaluations are expensive, time-consuming, or resource-intensive. It is widely used in scientific and engineering research to identify optimal conditions or parameters with minimal experimentation. To understand how BO works and why it is so effective, we need to explore its foundation in probabilistic modeling and how it leverages uncertainty to guide decision-making.</p>"},{"location":"background/bayesian_optimization/#why-use-bayesian-optimization","title":"Why Use Bayesian Optimization?","text":"<p>In many real-world problems, the objective function (the thing you want to optimize) is:</p> <ul> <li>Expensive to evaluate: Each experiment or simulation may require significant time, materials, or computational resources.</li> <li>Black-box in nature: You may not have an explicit mathematical formula for the objective function, only the ability to measure its output for given inputs.</li> <li>Noisy: Experimental results may vary due to measurement errors or uncontrollable factors.</li> </ul> <p>Traditional optimization methods, such as grid search or brute-force sampling, are inefficient in these scenarios because they require a large number of evaluations. Bayesian Optimization, on the other hand, is designed to minimize the number of evaluations by intelligently selecting the most informative experiments to perform.</p>"},{"location":"background/bayesian_optimization/#the-core-idea-probabilistic-modeling","title":"The Core Idea: Probabilistic Modeling","text":"<p>At the heart of Bayesian Optimization is a probabilistic model of the objective function. Unlike many machine learning models (e.g., neural networks or decision trees) that provide a single prediction for a given input, probabilistic models output a distribution of possible values. This distribution captures both the predicted value and the uncertainty in that prediction.</p>"},{"location":"background/bayesian_optimization/#gaussian-processes-gps","title":"Gaussian Processes (GPs)","text":"<p>The most common probabilistic model used in Bayesian Optimization is the Gaussian Process (GP). A GP is a flexible and powerful tool for modeling unknown functions. It assumes that the objective function can be described as a random process, where any finite set of points follows a multivariate Gaussian distribution.</p>"},{"location":"background/bayesian_optimization/#key-features-of-gaussian-processes","title":"Key Features of Gaussian Processes","text":"<ol> <li> <p>Mean Function: Represents the model's best guess for the objective function at any given point \\(x\\), denoted as \\(\\mu(x)\\).</p> </li> <li> <p>Covariance Function (Kernel): Describes how points in the input space are related, denoted as \\(k(x, x')\\). For example, points closer together are often assumed to have similar objective values. Common kernels include the Radial Basis Function (RBF) and Mat\u00e9rn kernels.</p> </li> <li> <p>Uncertainty Quantification: For each input \\(x\\), the GP provides both a predicted mean \\(\\mu(x)\\) and a standard deviation \\(\\sigma(x)\\), giving a full probability distribution for the objective value: \\(f(x) \\sim \\mathcal{N}(\\mu(x), \\sigma^2(x))\\).</p> </li> </ol> <p>This ability to quantify uncertainty is what sets GPs apart from many other machine learning models, such as neural networks or support vector machines, which typically provide only point estimates.</p>"},{"location":"background/bayesian_optimization/#how-bayesian-optimization-works","title":"How Bayesian Optimization Works","text":"<p>Bayesian Optimization uses the probabilistic model (e.g., a GP) to guide the search for the optimal input parameters. Here's how it works step by step:</p>"},{"location":"background/bayesian_optimization/#1-define-the-variable-space","title":"1. Define the Variable Space","text":"<p>The first step is to define the input variables (e.g., temperature, pressure, composition) and their ranges. These variables form the \"search space\" for optimization.</p>"},{"location":"background/bayesian_optimization/#2-build-the-surrogate-model","title":"2. Build the Surrogate Model","text":"<p>The surrogate model (e.g., a GP) is trained on a small set of initial data points. This model approximates the objective function and provides predictions with associated uncertainties.</p>"},{"location":"background/bayesian_optimization/#3-evaluate-the-acquisition-function","title":"3. Evaluate the Acquisition Function","text":"<p>The acquisition function is a mathematical rule that determines the next point to evaluate. It uses the surrogate model's predictions and uncertainties to balance two competing goals: - Exploration: Testing regions of the search space with high uncertainty to learn more about the objective function. - Exploitation: Testing regions likely to yield high objective values based on current knowledge.</p>"},{"location":"background/bayesian_optimization/#common-acquisition-functions","title":"Common Acquisition Functions","text":"<p>Expected Improvement (EI): Measures the expected improvement over the current best objective value. EI favors points with high predicted values and/or high uncertainty.</p> \\[ \\mathrm{EI}(x) = \\mathbb{E} \\left[ \\max(0, f(x) - f_\\text{best}) \\right] \\] <p>Probability of Improvement (PI): Focuses on the probability that a point will improve upon the current best value, where \\(\\Phi\\) is the cumulative distribution function of the standard normal distribution.</p> \\[ \\mathrm{PI}(x) = \\Phi \\left( \\frac{\\mu(x) - f_\\text{best}}{\\sigma(x)} \\right) \\] <p>Upper Confidence Bound (UCB): Balances exploration and exploitation by considering both the predicted mean and uncertainty, where \\(\\kappa\\) is a tunable parameter that controls the exploration-exploitation tradeoff.</p> \\[ \\mathrm{UCB}(x) = \\mu(x) + \\kappa \\cdot \\sigma(x) \\]"},{"location":"background/bayesian_optimization/#4-perform-the-experiment","title":"4. Perform the Experiment","text":"<p>The next experiment is conducted at the point suggested by the acquisition function, and the result is added to the dataset.</p>"},{"location":"background/bayesian_optimization/#5-update-the-model","title":"5. Update the Model","text":"<p>The surrogate model is retrained with the new data, refining its predictions and uncertainties.</p>"},{"location":"background/bayesian_optimization/#6-repeat-until-convergence","title":"6. Repeat Until Convergence","text":"<p>Steps 3\u20135 are repeated until the objective is optimized or resources are exhausted.</p>"},{"location":"background/bayesian_optimization/#why-probabilistic-modeling-matters","title":"Why Probabilistic Modeling Matters","text":"<p>The use of probabilistic models like GPs is what makes Bayesian Optimization so effective. By modeling uncertainty, GPs allow the optimization process to: - Focus on promising regions: Exploit areas likely to yield high objective values. - Explore unknown regions: Avoid getting stuck in local optima by testing areas with high uncertainty. - Adapt to noisy data: Account for variability in experimental results.</p> <p>This probabilistic approach ensures that every experiment contributes valuable information, making Bayesian Optimization highly efficient.</p>"},{"location":"background/bayesian_optimization/#example-optimizing-a-chemical-reaction","title":"Example: Optimizing a Chemical Reaction","text":"<p>Imagine you are optimizing a chemical reaction to maximize yield. The input variables are temperature, pressure, and catalyst loading, and the objective is the reaction yield. Each experiment is expensive, so you want to minimize the number of trials.</p> <ol> <li>Initial Data: Start with a few experiments at random conditions.</li> <li>Surrogate Model: Use a GP to model the relationship between the input variables and yield.</li> <li>Acquisition Function: Evaluate the acquisition function to select the next set of conditions to test.</li> <li>Experiment: Conduct the experiment and measure the yield.</li> <li>Update: Add the new data to the GP and repeat.</li> </ol> <p>Over time, Bayesian Optimization will focus on the most promising conditions, efficiently identifying the optimal reaction parameters.</p>"},{"location":"background/bayesian_optimization/#learn-more","title":"Learn More","text":"<p>For a visual and engaging overview of Bayesian Optimization, watch this excellent video by Taylor Sparks, Professor of Materials Science &amp; Engineering at the University of Utah: </p>"},{"location":"background/bayesian_optimization/#summary","title":"Summary","text":"<p>Bayesian Optimization is a powerful framework for optimizing complex systems with minimal experimentation. By leveraging probabilistic models like Gaussian Processes, it intelligently balances exploration and exploitation, making it ideal for applications where experiments are costly or time-consuming. Whether you're optimizing a chemical reaction, designing a new material, or tuning a process, Bayesian Optimization can help you achieve your goals more</p>"},{"location":"background/kernels/","title":"Kernel Deep Dive: Understanding Kernels in Gaussian Processes","text":"<p>Kernels (also called covariance functions) are a fundamental component of Gaussian Processes (GPs). They encode our assumptions about the underlying function we are modeling and play a central role in determining the GP's predictions and uncertainty.</p>"},{"location":"background/kernels/#what-is-a-kernel","title":"What Is a Kernel?","text":"<p>Mathematically, a kernel is a function \\(k(x, x')\\) that defines the similarity or correlation between two points \\(x\\) and \\(x'\\) in the input space. In a GP, the kernel determines the covariance matrix \\(\\mathbf{K}\\) for all pairs of input points, which in turn defines the joint distribution over function values.</p> <p>Given a set of input points \\(\\mathbf{X} = [x_1, x_2, ..., x_n]\\), the GP prior is:</p> \\[ f(\\mathbf{X}) \\sim \\mathcal{N}(\\mu(\\mathbf{X}), \\mathbf{K}) \\] <p>where \\(\\mathbf{K}_{ij} = k(x_i, x_j)\\).</p> <p>Functionally, the kernel controls: - The smoothness and complexity of the functions the GP can model. - How information from observed data points influences predictions at new points. - The ability to capture periodicity, trends, or other structural properties.</p>"},{"location":"background/kernels/#common-kernels","title":"Common Kernels","text":""},{"location":"background/kernels/#1-radial-basis-function-rbf-squared-exponential-gaussian-kernel","title":"1. Radial Basis Function (RBF) / Squared Exponential / Gaussian Kernel","text":"<p>The RBF kernel is the most widely used kernel and assumes the function is infinitely smooth.</p> \\[ k_{\\text{RBF}}(x, x') = \\sigma^2 \\exp\\left( -\\frac{||x - x'||^2}{2\\ell^2} \\right) \\] <ul> <li>\\(\\sigma^2\\) is the signal variance (controls overall scale).</li> <li>\\(\\ell\\) is the lengthscale (controls how quickly correlation decays with distance).</li> </ul> <p>Properties: - Produces very smooth functions. - Good default for many problems. - Implemented in both scikit-optimize and BoTorch.</p> <p>References: sklearn RBF kernel BoTorch RBF kernel</p>"},{"location":"background/kernels/#2-matern-kernel","title":"2. Matern Kernel","text":"<p>The Matern kernel is a generalization of the RBF kernel with an additional parameter \\(\\nu\\) that controls smoothness.</p> \\[ k_{\\text{Matern}}(x, x') = \\sigma^2 \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\frac{\\sqrt{2\\nu} ||x - x'||}{\\ell} \\right)^\\nu K_\\nu \\left( \\frac{\\sqrt{2\\nu} ||x - x'||}{\\ell} \\right) \\] <ul> <li>\\(\\nu\\) (nu): Smoothness parameter. Common values are 0.5, 1.5, 2.5, and \\(\\infty\\).<ul> <li>\\(\\nu = 0.5\\): Exponential kernel (less smooth, rougher functions)</li> <li>\\(\\nu = 1.5\\): Once differentiable</li> <li>\\(\\nu = 2.5\\): Twice differentiable</li> <li>\\(\\nu \\to \\infty\\): Recovers the RBF kernel</li> </ul> </li> <li>\\(K_\\nu\\) is a modified Bessel function.</li> </ul> <p>Properties: - Allows control over function roughness. - Lower \\(\\nu\\) allows modeling rougher, less smooth functions. - Implemented in both scikit-optimize and BoTorch.</p> <p>References: sklearn Matern kernel BoTorch Matern kernel</p>"},{"location":"background/kernels/#3-rational-quadratic-kernel","title":"3. Rational Quadratic Kernel","text":"<p>The Rational Quadratic kernel can be seen as a scale mixture of RBF kernels with different lengthscales.</p> \\[ k_{\\text{RQ}}(x, x') = \\sigma^2 \\left( 1 + \\frac{||x - x'||^2}{2\\alpha \\ell^2} \\right)^{-\\alpha} \\] <ul> <li>\\(\\alpha\\) controls the relative weighting of large-scale and small-scale variations.</li> <li>As \\(\\alpha \\to \\infty\\), the kernel approaches the RBF kernel.</li> </ul> <p>Properties: - Can model functions with varying smoothness. - Useful when the function exhibits both short- and long-range correlations. - Currently implemented in the scikit-optimize backend.</p> <p>References: sklearn RationalQuadratic kernel</p>"},{"location":"background/kernels/#anisotropic-kernels-and-automatic-relevance-determination-ard","title":"Anisotropic Kernels and Automatic Relevance Determination (ARD)","text":""},{"location":"background/kernels/#isotropic-vs-anisotropic","title":"Isotropic vs. Anisotropic","text":"<ul> <li> <p>Isotropic kernel: Uses a single lengthscale \\(\\ell\\) for all input dimensions.  </p> <p>\\(k(x, x') = k(||x - x'||)\\)</p> </li> <li> <p>Anisotropic kernel: Uses a separate lengthscale \\(\\ell_d\\) for each input dimension \\(d\\).  </p> <p>\\(k(x, x') = \\exp\\left( -\\sum_{d=1}^D \\frac{(x_d - x'_d)^2}{2\\ell_d^2} \\right)\\)</p> </li> </ul>"},{"location":"background/kernels/#automatic-relevance-determination-ard","title":"Automatic Relevance Determination (ARD)","text":"<p>ARD refers to the process where the model learns a separate lengthscale for each input variable. If a variable is not relevant to the output, its lengthscale will become very large, effectively reducing its influence on the model.</p> <p>Benefits: - Helps identify which variables are important for predicting the output. - Improves interpretability and can lead to more efficient optimization.</p> <p>Both scikit-optimize and BoTorch support anisotropic kernels and ARD by default.</p>"},{"location":"background/kernels/#choosing-a-kernel","title":"Choosing a Kernel","text":"<ul> <li>RBF: Good default for smooth, well-behaved functions.</li> <li>Matern: Use when you expect the function to be less smooth or want to control smoothness. Lower \\(\\nu\\) for rougher functions, higher \\(\\nu\\) for smoother.</li> <li>Rational Quadratic: Use when you suspect the function has varying smoothness or both short- and long-range correlations.</li> </ul> <p>Tips: - If unsure, start with Matern (\\(\\nu=2.5\\) or \\(1.5\\)) or RBF. - Try different kernels and compare cross-validation metrics (RMSE, MAE, etc.). - Use ARD to let the model determine variable relevance.</p>"},{"location":"background/kernels/#further-reading","title":"Further Reading","text":"<ul> <li>scikit-learn Gaussian Process kernels documentation</li> <li>scikit-optimize kernels</li> <li>BoTorch kernels</li> </ul>"},{"location":"modeling/botorch/","title":"BoTorch Backend","text":"<p>The BoTorch backend in ALchemist allows you to train a Gaussian Process (GP) surrogate model using the BoTorch library, which is built on PyTorch and designed for scalable Bayesian optimization. BoTorch provides advanced kernel options and efficient handling of both continuous and categorical variables.</p>"},{"location":"modeling/botorch/#what-is-botorch","title":"What is BoTorch?","text":"<p>BoTorch is a flexible, research-oriented library for Bayesian optimization built on PyTorch. It was developed by Meta (Facebook) and serves as the underlying optimization engine for Ax, a high-level adaptive experimentation platform. BoTorch supports advanced features such as anisotropic kernels (automatic relevance determination, ARD) and mixed-variable spaces, and is tightly integrated with GPyTorch for scalable Gaussian process inference.</p>"},{"location":"modeling/botorch/#training-a-model-with-botorch-backend","title":"Training a Model with BoTorch Backend","text":"<p>When you select the botorch backend in the Model panel, you are training a GP model using BoTorch's <code>SingleTaskGP</code> (for continuous variables) or <code>MixedSingleTaskGP</code> (for mixed continuous/categorical variables). The workflow and options are as follows:</p>"},{"location":"modeling/botorch/#1-kernel-selection","title":"1. Kernel Selection","text":"<p>You can choose the kernel type for the continuous variables:</p> <ul> <li>Matern: Default, with a tunable smoothness parameter (<code>nu</code>).</li> <li>RBF: Radial Basis Function kernel.</li> </ul> <p>For the Matern kernel, you can select the <code>nu</code> parameter (0.5, 1.5, or 2.5), which controls the smoothness of the function.</p> <p>Note: BoTorch uses anisotropic (ARD) kernels by default, so each variable can have its own learned lengthscale. This helps preserve the physical meaning of each variable and enables automatic relevance detection. For more details, see the Kernel Deep Dive in the Educational Resources section.</p>"},{"location":"modeling/botorch/#2-categorical-variables","title":"2. Categorical Variables","text":"<ul> <li>Categorical variables are automatically detected and encoded.</li> <li>BoTorch uses the <code>MixedSingleTaskGP</code> model to handle mixed spaces, encoding categorical variables as required.</li> </ul>"},{"location":"modeling/botorch/#3-noise-handling","title":"3. Noise Handling","text":"<ul> <li>If your experimental data includes a <code>Noise</code> column, these values are used for regularization.</li> <li>If not, the model uses its internal noise estimation.</li> </ul>"},{"location":"modeling/botorch/#4-model-training-and-evaluation","title":"4. Model Training and Evaluation","text":"<ul> <li>The model is trained on your current experiment data.</li> <li>Cross-validation is performed to estimate model performance (RMSE, MAE, MAPE, R\u00b2).</li> <li>Learned kernel hyperparameters (lengthscales, outputscale, etc.) are displayed after training.</li> </ul>"},{"location":"modeling/botorch/#5-advanced-options","title":"5. Advanced Options","text":"<ul> <li>You can select the kernel type and Matern <code>nu</code> parameter in the Model panel.</li> <li>BoTorch uses sensible defaults for other training parameters.</li> </ul>"},{"location":"modeling/botorch/#how-it-works","title":"How It Works","text":"<ul> <li>The model uses your variable space and experiment data to fit a GP regression model using PyTorch.</li> <li>The trained model is used for Bayesian optimization, suggesting new experiments via acquisition functions.</li> <li>All preprocessing (encoding, noise handling) is handled automatically.</li> </ul>"},{"location":"modeling/botorch/#references","title":"References","text":"<ul> <li>BoTorch documentation</li> <li>BoTorch SingleTaskGP</li> <li>BoTorch MixedSingleTaskGP</li> <li>Ax platform documentation</li> <li>GPyTorch documentation</li> </ul> <p>For a deeper explanation of kernel selection, anisotropic kernels, and ARD, see Kernel Deep Dive in the Educational Resources section.</p> <p>For details on using the scikit-optimize backend, see the previous section.</p>"},{"location":"modeling/performance/","title":"Model Performance","text":"<p>Evaluating the performance of your surrogate model is a critical step in the active learning workflow. ALchemist provides several tools and visualizations to help you assess model quality and guide your next steps.</p>"},{"location":"modeling/performance/#cross-validation-and-error-metrics","title":"Cross-Validation and Error Metrics","text":"<p>After training a model, ALchemist automatically computes cross-validation metrics such as RMSE, MAE, MAPE, and R\u00b2. These metrics are visualized in the Visualizations dialog, where you can see how model error changes as more data points are added.</p> <p>General expectation: - As you increase the number of observations, cross-validation error (e.g., RMSE) should generally decrease. This indicates that the model is learning from the data and improving its predictions.</p>"},{"location":"modeling/performance/#what-if-error-doesnt-decrease","title":"What if Error Doesn't Decrease?","text":"<p>If you notice that error metrics do not decrease with more data, consider the following:</p> <ol> <li> <p>Small Data Regime (&lt;10 points):    With very few data points, high error or flat trends are common. This is not necessarily a problem\u2014acquisition functions will naturally suggest new experiments in regions of high uncertainty, helping the model converge as more data is collected.</p> </li> <li> <p>Try a Different Backend:    Switch between the scikit-optimize and BoTorch backends. Sometimes one backend may fit your data better, especially depending on the variable types and dimensionality.</p> </li> <li> <p>Tweak the Kernel:    Experiment with different kernel types (RBF, Matern, RationalQuadratic) or adjust the Matern <code>nu</code> parameter. The choice of kernel can significantly affect model flexibility and fit.</p> </li> </ol>"},{"location":"modeling/performance/#additional-tips-and-considerations","title":"Additional Tips and Considerations","text":"<ul> <li> <p>Overfitting:   Overfitting may appear as jagged or unrealistic response surfaces in contour plots. If you see this, try increasing regularization (e.g., by specifying higher noise values) or collecting more data.</p> </li> <li> <p>Data Quality:   Poor model performance can result from poor data quality. Check for outliers or inconsistent measurements. Consider populating the <code>Noise</code> column with an appropriate metric (such as variance or signal-to-noise ratio) to help regularize the model. See the Regularization page for more details.</p> </li> <li> <p>Model Diagnostics:   Use parity plots and error metric trends to diagnose underfitting, overfitting, or data issues. Ideally, parity plots should show points close to the diagonal (y = x), indicating good agreement between predicted and actual values.</p> </li> <li> <p>Variable Importance:   Both backends use anisotropic (ARD) kernels by default, allowing the model to learn a separate lengthscale for each variable. This can help identify which variables are most relevant to the output.</p> </li> </ul>"},{"location":"modeling/performance/#summary","title":"Summary","text":"<ul> <li>Expect error to decrease as more data is added.</li> <li>Use backend and kernel options to improve fit.</li> <li>Watch for signs of overfitting or poor data quality.</li> <li>Use regularization and noise estimates to stabilize the model.</li> </ul> <p>For more on error metrics and visualization, see the Visualizations section.</p>"},{"location":"modeling/skopt/","title":"scikit-optimize Backend","text":"<p>The scikit-optimize backend in ALchemist allows you to train a Gaussian Process (GP) surrogate model using the <code>skopt.learning.GaussianProcessRegressor</code>, which is a wrapper around <code>sklearn.gaussian_process.GaussianProcessRegressor</code> designed specifically for Bayesian optimization workflows.</p>"},{"location":"modeling/skopt/#what-is-scikit-optimize","title":"What is scikit-optimize?","text":"<p>scikit-optimize (skopt) is a library built on top of scikit-learn that provides tools for sequential model-based optimization, commonly used in Bayesian optimization. In ALchemist, the skopt backend leverages this framework to efficiently model your experimental data and suggest new experiments.</p>"},{"location":"modeling/skopt/#training-a-model-with-scikit-learn-backend","title":"Training a Model with scikit-learn Backend","text":"<p>When you select the scikit-learn backend in the Model panel, you are training a Gaussian Process model using the skopt/scikit-learn stack. The workflow and options are as follows:</p>"},{"location":"modeling/skopt/#1-kernel-selection","title":"1. Kernel Selection","text":"<p>You can choose from several kernel types for the GP:</p> <ul> <li>RBF (Radial Basis Function): Default, smooth kernel.</li> <li>Matern: Flexible kernel with a tunable smoothness parameter (<code>nu</code>).</li> <li>RationalQuadratic: Mixture of RBF kernels with varying length scales.</li> </ul> <p>For the Matern kernel, you can select the <code>nu</code> parameter (0.5, 1.5, 2.5, or \u221e), which controls the smoothness of the function.</p> <p>Note: ALchemist uses anisotropic (dimension-wise) kernels by default, so each variable can have its own learned lengthscale. This helps preserve the physical meaning of each variable and enables automatic relevance detection (ARD). For more details, see the Kernel Deep Dive in the Educational Resources section.</p>"},{"location":"modeling/skopt/#2-optimizer","title":"2. Optimizer","text":"<p>You can select the optimizer used for hyperparameter tuning:</p> <ul> <li>L-BFGS-B (default)</li> <li>CG</li> <li>BFGS</li> <li>TNC</li> </ul> <p>These control how the kernel hyperparameters are optimized during model fitting.</p>"},{"location":"modeling/skopt/#3-advanced-options","title":"3. Advanced Options","text":"<p>Enable advanced options to customize kernel and optimizer settings. By default, kernel hyperparameters are automatically optimized.</p>"},{"location":"modeling/skopt/#4-noise-handling","title":"4. Noise Handling","text":"<p>If your experimental data includes a <code>Noise</code> column, these values are used for regularization (<code>alpha</code> parameter in scikit-learn). If not, the model uses its default regularization.</p>"},{"location":"modeling/skopt/#5-one-hot-encoding","title":"5. One-Hot Encoding","text":"<p>Categorical variables are automatically one-hot encoded for compatibility with scikit-learn.</p>"},{"location":"modeling/skopt/#6-model-training-and-evaluation","title":"6. Model Training and Evaluation","text":"<ul> <li>The model is trained on your current experiment data.</li> <li>Cross-validation is performed to estimate model performance (RMSE, MAE, MAPE, R\u00b2).</li> <li>Learned kernel hyperparameters are displayed after training.</li> </ul>"},{"location":"modeling/skopt/#how-it-works","title":"How It Works","text":"<ul> <li>The model uses your variable space and experiment data to fit a GP regression model.</li> <li>The trained model is used for Bayesian optimization, suggesting new experiments via acquisition functions.</li> <li>All preprocessing (encoding, noise handling) is handled automatically.</li> </ul>"},{"location":"modeling/skopt/#references","title":"References","text":"<ul> <li>scikit-learn GaussianProcessRegressor documentation</li> <li>scikit-optimize GaussianProcessRegressor documentation</li> </ul> <p>For a deeper explanation of kernel selection, anisotropic kernels, and ARD, see Kernel Deep Dive in the Educational Resources section.</p> <p>For details on using the BoTorch backend, see the next section.</p>"},{"location":"setup/data_visualization/","title":"Data Visualization","text":"<p>The Visualization panel in ALchemist displays a 2D scatter plot of your experiment data and search space.</p> <ul> <li> <p>Variable Selection:   Use the dropdown menus above the plot to choose which variables to display on the x and y axes.</p> </li> <li> <p>Pool Points:   Light blue, semi-transparent dots represent the pool of potential experiment points generated from your variable space.</p> </li> <li> <p>Sampled Points:   Green dots show the experiments you have already run or loaded.</p> </li> <li> <p>Suggested Next Point:   A blue diamond marker will appear after you train a model and run an acquisition function, indicating the next recommended experiment.</p> </li> </ul> <p>Currently, only 2D scatter plots are supported. Future updates may add more visualization options, such as 3D plots or advanced data views.</p>"},{"location":"setup/initial_sampling/","title":"Generating Initial Experiments","text":"<p>When starting an active learning workflow, it's important to generate an initial set of experiments that cover your variable space efficiently. This is especially useful if you have no prior experimental data, or if your existing data was not collected with surrogate modeling in mind. Well-chosen initial points help ensure that your model converges efficiently and avoids bias from poor coverage.</p>"},{"location":"setup/initial_sampling/#why-generate-initial-points","title":"Why Generate Initial Points?","text":"<ul> <li>No Prior Data: If you are starting from scratch, you need a set of initial experiments to train your first surrogate model.</li> <li>Supplement Existing Data: If you have some data, but it is sparse or not well-distributed, you can generate additional points to improve coverage.</li> <li>Efficient Model Convergence: Good initial coverage of the variable space helps the model learn faster and reduces the risk of missing important regions.</li> </ul>"},{"location":"setup/initial_sampling/#how-to-generate-initial-points","title":"How to Generate Initial Points","text":"<ol> <li> <p>Load or Define Your Variable Space:    Make sure you have set up your variable space using the Variable Space Setup dialog.</p> </li> <li> <p>Open the Initial Sampling Dialog:    In the main application window, click Generate Initial Points in the Experiment Data panel.</p> </li> <li> <p>Choose a Sampling Strategy:    Select from several strategies:</p> </li> <li>Random: Uniformly samples points at random.</li> <li>LHS (Latin Hypercube Sampling): Ensures each variable is sampled evenly across its range.</li> <li> <p>Sobol, Halton, Hammersly: Quasi-random low-discrepancy sequences for more uniform coverage in high dimensions.</p> </li> <li> <p>Set the Number of Points:    Enter how many initial experiments you want to generate.</p> </li> <li> <p>Generate and Review:    Click Generate. The new points will appear in your experiment table, ready for export or further editing.</p> </li> </ol>"},{"location":"setup/initial_sampling/#tips","title":"Tips","text":"<ul> <li>Coverage Matters: More points give better coverage, but also require more experiments. Balance your resources and modeling needs.</li> <li>Quasi-Random vs. Random: Quasi-random methods (LHS, Sobol, etc.) are generally preferred for initial sampling, especially in higher dimensions.</li> <li>Supplementing Data: You can generate initial points even if you already have some data, to fill gaps or improve distribution.</li> </ul>"},{"location":"setup/initial_sampling/#example-workflow","title":"Example Workflow","text":"<ol> <li>Define your variable space (e.g., 3 variables: temperature, pressure, catalyst).</li> <li>Click Generate Initial Points.</li> <li>Choose LHS and set Number of Points to 10.</li> <li>Click Generate.</li> <li>Review the generated points in the experiment table and save to file if desired.</li> </ol> <p>For more details on experiment management and data loading, see the next section of the workflow documentation.</p>"},{"location":"setup/load_data/","title":"Loading Experimental Data","text":"<p>The Experiment Data panel in ALchemist lets you load, view, and manage your experimental results. This is a key step before training surrogate models or running active learning.</p>"},{"location":"setup/load_data/#loading-data-from-file","title":"Loading Data from File","text":"<ol> <li>Click \"Load Experiments\":    In the Experiment Data panel, click the Load Experiments button.</li> <li>Select Your File:    Choose a <code>.csv</code> file containing your experimental data. The file should have columns for each variable (matching your variable space) and an <code>Output</code> column for the measured result. Optionally, you can include a <code>Noise</code> column to specify measurement uncertainty for each point.</li> <li>Data Appears in the Table:    The loaded data will be displayed in the table. If a <code>Noise</code> column is present, it will be used for model regularization.</li> </ol> <p>Tip: If your data columns do not match the variable names or required format, you may see an error. Make sure your CSV headers match your variable space exactly.</p>"},{"location":"setup/load_data/#adding-a-new-experiment-point","title":"Adding a New Experiment Point","text":"<p>You can add a new experiment directly from the UI:</p> <ol> <li>Click \"Add Point\":    Opens a dialog where you can enter values for each variable, the output, and (optionally) the noise.</li> <li>Fill in the Fields:    Enter values for all variables and the output. If you know the measurement uncertainty, enter it in the Noise field.</li> <li>Save &amp; Close:    Click Save &amp; Close to add the point to your experiment table. You can also choose to save the updated data to file and retrain the model immediately by checking the corresponding boxes.</li> </ol> <p>Note: - There may be issues with type compatibility (e.g., numbers being saved as strings). If you encounter problems, check your CSV file and ensure numeric columns are formatted correctly. - Sometimes, changes made directly in the table (tksheet widget) may not update the internal experiment data until you save or reload. Use the provided dialogs for best results.</p>"},{"location":"setup/load_data/#saving-your-data","title":"Saving Your Data","text":"<ul> <li>Click \"Save Experiments\":   Saves the current experiment table to a <code>.csv</code> file.  </li> <li>Tip:   Always save your data before closing the application to avoid losing changes.</li> </ul>"},{"location":"setup/load_data/#retraining-the-model","title":"Retraining the Model","text":"<ul> <li>When adding a new point, you can check Retrain model to automatically update the surrogate model with the new data.</li> <li>If retraining does not seem to trigger, you may need to retrain manually from the model panel.</li> </ul>"},{"location":"setup/load_data/#known-issues-tips","title":"Known Issues &amp; Tips","text":"<ul> <li>Type Compatibility:   Data entered via the table or add-point dialog may sometimes be interpreted as strings. If you see errors or unexpected behavior, check your data types in the CSV file.</li> <li>Table Edits:   Editing data directly in the table does not always update the internal experiment manager. For reliable results, use the add-point dialog or reload your data after editing.</li> <li>Noise Column:   The noise column is optional. If present, it should be numeric. You can toggle its visibility in the Preferences menu.</li> </ul> <p>For more details on managing experiments and troubleshooting, see the rest of the workflow documentation.</p>"},{"location":"setup/variable_space/","title":"Setting Up the Variable Space","text":"<p>The Variable Space Setup window allows you to define the variables that make up your search space for active learning experiments. This user guide explains each part of the dialog and how to use it.</p>"},{"location":"setup/variable_space/#opening-the-variable-space-setup","title":"Opening the Variable Space Setup","text":"<ul> <li>Click the Define Search Space button in the main application window to open the setup dialog.</li> </ul>"},{"location":"setup/variable_space/#window-overview","title":"Window Overview","text":"<p>The window is divided into two main sections:</p> <ul> <li>Left Panel: Displays a list of variables you have defined.</li> <li>Right Panel: Contains control buttons for managing variables.</li> </ul>"},{"location":"setup/variable_space/#adding-and-editing-variables","title":"Adding and Editing Variables","text":"<p>Each variable is represented as a row with the following fields:</p> <ul> <li>Variable Name: Enter a unique name for your variable.</li> <li>Type: Choose the variable type from the dropdown:</li> <li><code>Real</code>: For continuous variables (e.g., floating-point numbers).</li> <li><code>Integer</code>: For discrete variables (e.g., whole numbers).</li> <li><code>Categorical</code>: For variables with a set of named categories.</li> </ul> <p>Depending on the type selected: - Real/Integer: Enter minimum and maximum values in the <code>Min</code> and <code>Max</code> fields. - Categorical: Click Edit Values to open a dialog where you can enter possible category values (one per row). Click Save in the dialog to confirm.</p>"},{"location":"setup/variable_space/#managing-variable-rows","title":"Managing Variable Rows","text":"<p>Use the buttons on the right panel to manage your variable list:</p> <ul> <li>Add Variable: Add a new variable row.</li> <li>Delete Row: Remove the currently selected variable.</li> <li>Clear Row: Clear all fields in the selected row.</li> <li>Move Up/Down: Change the order of variables by moving the selected row up or down.</li> </ul> <p>Click on a row to select it; the selected row is highlighted.</p>"},{"location":"setup/variable_space/#saving-and-loading","title":"Saving and Loading","text":"<ul> <li>Save to File: Save your variable definitions to a <code>.json</code> or <code>.csv</code> file.</li> <li>Load from File: Load variable definitions from a <code>.json</code> or <code>.csv</code> file.</li> <li>Save &amp; Close: Save your current variable space and close the window. This also updates the application's internal search space.</li> </ul>"},{"location":"setup/variable_space/#tips","title":"Tips","text":"<ul> <li>All fields must be filled out for a variable to be valid.</li> <li>For categorical variables, you must specify at least one value.</li> <li>You can reorder variables to control their order in the search space.</li> </ul>"},{"location":"setup/variable_space/#example","title":"Example","text":"Variable Name Type Min Max Values temperature Real 20 100 batch_size Integer 1 10 catalyst Categorical A, B, C, D <p>For more details on how the variable space is used, see the rest of the workflow documentation.</p>"},{"location":"visualizations/contour_plot/","title":"Contour Plot Visualization","text":"<p>The Contour Plot feature in ALchemist lets you visualize your surrogate model\u2019s predicted output as a 2D contour plot, providing insight into the model\u2019s response surface across your variable space. This tool is designed for interpreting model predictions, identifying trends, and creating publication-quality figures.</p>"},{"location":"visualizations/contour_plot/#how-to-create-a-contour-plot","title":"How to Create a Contour Plot","text":"<ol> <li> <p>Open the Visualizations Dialog:    After training a model, open the Visualizations dialog from the main application window.</p> </li> <li> <p>Choose X and Y Axes:    Use the dropdown menus in the \"Contour Plot Options\" panel to select which two real-valued variables to display on the X and Y axes.</p> </li> <li> <p>Set Fixed Values for Other Variables:    Set a value for each remaining variable using the provided controls. This lets you view a \u201cslice\u201d of the model\u2019s prediction at a specific cross-section.</p> </li> <li> <p>Plot the Contour:    Click Plot Contour to generate the plot for your selected axes and fixed values. The predicted output will be shown as filled contours.</p> </li> </ol>"},{"location":"visualizations/contour_plot/#customization-and-export","title":"Customization and Export","text":"<ul> <li> <p>Customize Appearance:   Click Customize Plot to adjust the plot title, axis labels, colormap, font, font size, axis limits, font weight, tick style, and whether to show experimental data points (white circles) and the next suggested point (red diamond).</p> </li> <li> <p>Save Figures:   Use the Matplotlib toolbar below the plot to save your figure as a high-resolution image (PNG, SVG, PDF, etc.) for publication or presentations.</p> </li> </ul>"},{"location":"visualizations/contour_plot/#additional-features","title":"Additional Features","text":"<ul> <li>Interactive Controls:   Changing the X or Y axis or adjusting fixed values for other variables will update the plot in real time.</li> <li>Legend:   The plot includes a legend for experimental points and the next suggested point if displayed.</li> <li>Hyperparameters Display:   The bottom of the Visualizations dialog shows the learned kernel hyperparameters from the trained model.</li> </ul>"},{"location":"visualizations/contour_plot/#tips","title":"Tips","text":"<ul> <li>Use customization options to match your figure style to journal or presentation requirements.</li> <li>Generate multiple contour plots for different variable pairs and fixed values to explore the model\u2019s predictions.</li> <li>Contour plots are useful for diagnosing model behavior, visualizing optima, and communicating results.</li> </ul> <p>For more on model evaluation and error metrics, see the Error Metrics Visualization section.</p>"},{"location":"visualizations/error_metrics/","title":"Error Metrics Visualization","text":"<p>The Visualizations dialog in ALchemist provides several tools to help you evaluate your surrogate model's performance using different error metrics. After training a model, you can access these visualizations to better understand how your model is performing as you add more experimental data.</p>"},{"location":"visualizations/error_metrics/#available-error-metrics","title":"Available Error Metrics","text":"<p>You can select and plot the following metrics in the Visualizations dialog:</p> <ul> <li>RMSE (Root Mean Squared Error):   Measures the average magnitude of prediction errors. Lower RMSE indicates better fit. Sensitive to large errors.</li> </ul> \\[ \\mathrm{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 } \\] <ul> <li>MAE (Mean Absolute Error):   The average of absolute differences between predicted and actual values. Less sensitive to outliers than RMSE.</li> </ul> \\[ \\mathrm{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\] <ul> <li>MAPE (Mean Absolute Percentage Error):   Expresses prediction error as a percentage of the actual values. Useful for comparing errors across different scales, but can be unstable if actual values are near zero.</li> </ul> \\[ \\mathrm{MAPE} = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\] <ul> <li>\\(R^2\\) (Coefficient of Determination):   Indicates how well the model explains the variance in the data. Values closer to 1 mean better fit; values near 0 or negative indicate poor fit.</li> </ul> \\[ R^2 = 1 - \\frac{ \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }{ \\sum_{i=1}^{n} (y_i - \\bar{y})^2 } \\] <p>Where: - \\(y_i\\) = true value - \\(\\hat{y}_i\\) = predicted value - \\(\\bar{y}\\) = mean of true values - \\(n\\) = number of data points</p>"},{"location":"visualizations/error_metrics/#using-the-visualizations-dialog","title":"Using the Visualizations Dialog","text":"<ul> <li> <p>Plotting Metrics:   Use the dropdown menu at the top of the Visualizations dialog to select which error metric to plot. Click \"Plot Metrics\" to see how the chosen metric changes as more data points are added.</p> </li> <li> <p>Interpreting Trends:   Ideally, error metrics (RMSE, MAE, MAPE) should decrease as you add more observations, and \\(R^2\\) should increase. Flat or increasing error trends may indicate issues with model fit, data quality, or kernel choice.</p> </li> <li> <p>Cross-Validation:   All metrics are computed using cross-validation, providing a robust estimate of model performance on unseen data.</p> </li> <li> <p>Parity Plots:   In addition to error metrics, you can generate parity plots to visually compare predicted vs. actual values. Points close to the diagonal indicate good agreement.</p> </li> </ul>"},{"location":"visualizations/error_metrics/#general-considerations","title":"General Considerations","text":"<ul> <li>Use error metric trends to monitor model improvement as you collect more data.</li> <li>Compare different metrics for a more complete picture of model performance.</li> <li>If you see unexpected trends, refer to the Model Performance page for troubleshooting tips and deeper guidance.</li> </ul> <p>For more on interpreting these metrics and improving model performance, see the Model Performance section.</p>"}]}