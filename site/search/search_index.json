{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ALchemist","text":"<p>ALchemist is a GUI-based active learning and Bayesian optimization toolkit for chemical and materials researchers.</p> <p>Use the sidebar to navigate through the documentation.</p>"},{"location":"modeling/skopt/","title":"scikit-optimize Backend","text":"<p>The scikit-optimize backend in ALchemist allows you to train a Gaussian Process (GP) surrogate model using the <code>skopt.learning.GaussianProcessRegressor</code>, which is a wrapper around <code>sklearn.gaussian_process.GaussianProcessRegressor</code> designed specifically for Bayesian optimization workflows.</p>"},{"location":"modeling/skopt/#what-is-scikit-optimize","title":"What is scikit-optimize?","text":"<p>scikit-optimize (skopt) is a library built on top of scikit-learn that provides tools for sequential model-based optimization, commonly used in Bayesian optimization. In ALchemist, the skopt backend leverages this framework to efficiently model your experimental data and suggest new experiments.</p>"},{"location":"modeling/skopt/#training-a-model-with-scikit-learn-backend","title":"Training a Model with scikit-learn Backend","text":"<p>When you select the scikit-learn backend in the Model panel, you are training a Gaussian Process model using the skopt/scikit-learn stack. The workflow and options are as follows:</p>"},{"location":"modeling/skopt/#1-kernel-selection","title":"1. Kernel Selection","text":"<p>You can choose from several kernel types for the GP:</p> <ul> <li>RBF (Radial Basis Function): Default, smooth kernel.</li> <li>Matern: Flexible kernel with a tunable smoothness parameter (<code>nu</code>).</li> <li>RationalQuadratic: Mixture of RBF kernels with varying length scales.</li> </ul> <p>For the Matern kernel, you can select the <code>nu</code> parameter (0.5, 1.5, 2.5, or \u221e), which controls the smoothness of the function.</p> <p>Note: ALchemist uses anisotropic (dimension-wise) kernels by default, so each variable can have its own learned lengthscale. This helps preserve the physical meaning of each variable and enables automatic relevance detection (ARD). For more details, see the Kernel Deep Dive in the Educational Resources section.</p>"},{"location":"modeling/skopt/#2-optimizer","title":"2. Optimizer","text":"<p>You can select the optimizer used for hyperparameter tuning:</p> <ul> <li>L-BFGS-B (default)</li> <li>CG</li> <li>BFGS</li> <li>TNC</li> </ul> <p>These control how the kernel hyperparameters are optimized during model fitting.</p>"},{"location":"modeling/skopt/#3-advanced-options","title":"3. Advanced Options","text":"<p>Enable advanced options to customize kernel and optimizer settings. By default, kernel hyperparameters are automatically optimized.</p>"},{"location":"modeling/skopt/#4-noise-handling","title":"4. Noise Handling","text":"<p>If your experimental data includes a <code>Noise</code> column, these values are used for regularization (<code>alpha</code> parameter in scikit-learn). If not, the model uses its default regularization.</p>"},{"location":"modeling/skopt/#5-one-hot-encoding","title":"5. One-Hot Encoding","text":"<p>Categorical variables are automatically one-hot encoded for compatibility with scikit-learn.</p>"},{"location":"modeling/skopt/#6-model-training-and-evaluation","title":"6. Model Training and Evaluation","text":"<ul> <li>The model is trained on your current experiment data.</li> <li>Cross-validation is performed to estimate model performance (RMSE, MAE, MAPE, R\u00b2).</li> <li>Learned kernel hyperparameters are displayed after training.</li> </ul>"},{"location":"modeling/skopt/#how-it-works","title":"How It Works","text":"<ul> <li>The model uses your variable space and experiment data to fit a GP regression model.</li> <li>The trained model is used for Bayesian optimization, suggesting new experiments via acquisition functions.</li> <li>All preprocessing (encoding, noise handling) is handled automatically.</li> </ul>"},{"location":"modeling/skopt/#references","title":"References","text":"<ul> <li>scikit-learn GaussianProcessRegressor documentation</li> <li>scikit-optimize GaussianProcessRegressor documentation</li> </ul> <p>For a deeper explanation of kernel selection, anisotropic kernels, and ARD, see Kernel Deep Dive in the Educational Resources section.</p> <p>For details on using the BoTorch backend, see the next section.</p>"},{"location":"workflow/data_visualization/","title":"Data Visualization","text":"<p>The Visualization panel in ALchemist displays a 2D scatter plot of your experiment data and search space.</p> <ul> <li> <p>Variable Selection:   Use the dropdown menus above the plot to choose which variables to display on the x and y axes.</p> </li> <li> <p>Pool Points:   Light blue, semi-transparent dots represent the pool of potential experiment points generated from your variable space.</p> </li> <li> <p>Sampled Points:   Green dots show the experiments you have already run or loaded.</p> </li> <li> <p>Suggested Next Point:   A blue diamond marker will appear after you train a model and run an acquisition function, indicating the next recommended experiment.</p> </li> </ul> <p>Currently, only 2D scatter plots are supported. Future updates may add more visualization options, such as 3D plots or advanced data views.</p>"},{"location":"workflow/initial_sampling/","title":"Generating Initial Experiments","text":"<p>When starting an active learning workflow, it's important to generate an initial set of experiments that cover your variable space efficiently. This is especially useful if you have no prior experimental data, or if your existing data was not collected with surrogate modeling in mind. Well-chosen initial points help ensure that your model converges efficiently and avoids bias from poor coverage.</p>"},{"location":"workflow/initial_sampling/#why-generate-initial-points","title":"Why Generate Initial Points?","text":"<ul> <li>No Prior Data: If you are starting from scratch, you need a set of initial experiments to train your first surrogate model.</li> <li>Supplement Existing Data: If you have some data, but it is sparse or not well-distributed, you can generate additional points to improve coverage.</li> <li>Efficient Model Convergence: Good initial coverage of the variable space helps the model learn faster and reduces the risk of missing important regions.</li> </ul>"},{"location":"workflow/initial_sampling/#how-to-generate-initial-points","title":"How to Generate Initial Points","text":"<ol> <li> <p>Load or Define Your Variable Space:    Make sure you have set up your variable space using the Variable Space Setup dialog.</p> </li> <li> <p>Open the Initial Sampling Dialog:    In the main application window, click Generate Initial Points in the Experiment Data panel.</p> </li> <li> <p>Choose a Sampling Strategy:    Select from several strategies:</p> </li> <li>Random: Uniformly samples points at random.</li> <li>LHS (Latin Hypercube Sampling): Ensures each variable is sampled evenly across its range.</li> <li> <p>Sobol, Halton, Hammersly: Quasi-random low-discrepancy sequences for more uniform coverage in high dimensions.</p> </li> <li> <p>Set the Number of Points:    Enter how many initial experiments you want to generate.</p> </li> <li> <p>Generate and Review:    Click Generate. The new points will appear in your experiment table, ready for export or further editing.</p> </li> </ol>"},{"location":"workflow/initial_sampling/#tips","title":"Tips","text":"<ul> <li>Coverage Matters: More points give better coverage, but also require more experiments. Balance your resources and modeling needs.</li> <li>Quasi-Random vs. Random: Quasi-random methods (LHS, Sobol, etc.) are generally preferred for initial sampling, especially in higher dimensions.</li> <li>Supplementing Data: You can generate initial points even if you already have some data, to fill gaps or improve distribution.</li> </ul>"},{"location":"workflow/initial_sampling/#example-workflow","title":"Example Workflow","text":"<ol> <li>Define your variable space (e.g., 3 variables: temperature, pressure, catalyst).</li> <li>Click Generate Initial Points.</li> <li>Choose LHS and set Number of Points to 10.</li> <li>Click Generate.</li> <li>Review the generated points in the experiment table and save to file if desired.</li> </ol> <p>For more details on experiment management and data loading, see the next section of the workflow documentation.</p>"},{"location":"workflow/load_data/","title":"Loading Experimental Data","text":"<p>The Experiment Data panel in ALchemist lets you load, view, and manage your experimental results. This is a key step before training surrogate models or running active learning.</p>"},{"location":"workflow/load_data/#loading-data-from-file","title":"Loading Data from File","text":"<ol> <li>Click \"Load Experiments\":    In the Experiment Data panel, click the Load Experiments button.</li> <li>Select Your File:    Choose a <code>.csv</code> file containing your experimental data. The file should have columns for each variable (matching your variable space) and an <code>Output</code> column for the measured result. Optionally, you can include a <code>Noise</code> column to specify measurement uncertainty for each point.</li> <li>Data Appears in the Table:    The loaded data will be displayed in the table. If a <code>Noise</code> column is present, it will be used for model regularization.</li> </ol> <p>Tip: If your data columns do not match the variable names or required format, you may see an error. Make sure your CSV headers match your variable space exactly.</p>"},{"location":"workflow/load_data/#adding-a-new-experiment-point","title":"Adding a New Experiment Point","text":"<p>You can add a new experiment directly from the UI:</p> <ol> <li>Click \"Add Point\":    Opens a dialog where you can enter values for each variable, the output, and (optionally) the noise.</li> <li>Fill in the Fields:    Enter values for all variables and the output. If you know the measurement uncertainty, enter it in the Noise field.</li> <li>Save &amp; Close:    Click Save &amp; Close to add the point to your experiment table. You can also choose to save the updated data to file and retrain the model immediately by checking the corresponding boxes.</li> </ol> <p>Note: - There may be issues with type compatibility (e.g., numbers being saved as strings). If you encounter problems, check your CSV file and ensure numeric columns are formatted correctly. - Sometimes, changes made directly in the table (tksheet widget) may not update the internal experiment data until you save or reload. Use the provided dialogs for best results.</p>"},{"location":"workflow/load_data/#saving-your-data","title":"Saving Your Data","text":"<ul> <li>Click \"Save Experiments\":   Saves the current experiment table to a <code>.csv</code> file.  </li> <li>Tip:   Always save your data before closing the application to avoid losing changes.</li> </ul>"},{"location":"workflow/load_data/#retraining-the-model","title":"Retraining the Model","text":"<ul> <li>When adding a new point, you can check Retrain model to automatically update the surrogate model with the new data.</li> <li>If retraining does not seem to trigger, you may need to retrain manually from the model panel.</li> </ul>"},{"location":"workflow/load_data/#known-issues-tips","title":"Known Issues &amp; Tips","text":"<ul> <li>Type Compatibility:   Data entered via the table or add-point dialog may sometimes be interpreted as strings. If you see errors or unexpected behavior, check your data types in the CSV file.</li> <li>Table Edits:   Editing data directly in the table does not always update the internal experiment manager. For reliable results, use the add-point dialog or reload your data after editing.</li> <li>Noise Column:   The noise column is optional. If present, it should be numeric. You can toggle its visibility in the Preferences menu.</li> </ul> <p>For more details on managing experiments and troubleshooting, see the rest of the workflow documentation.</p>"},{"location":"workflow/variable_space/","title":"Setting Up the Variable Space","text":"<p>The Variable Space Setup window allows you to define the variables that make up your search space for active learning experiments. This user guide explains each part of the dialog and how to use it.</p>"},{"location":"workflow/variable_space/#opening-the-variable-space-setup","title":"Opening the Variable Space Setup","text":"<ul> <li>Click the Define Search Space button in the main application window to open the setup dialog.</li> </ul>"},{"location":"workflow/variable_space/#window-overview","title":"Window Overview","text":"<p>The window is divided into two main sections:</p> <ul> <li>Left Panel: Displays a list of variables you have defined.</li> <li>Right Panel: Contains control buttons for managing variables.</li> </ul>"},{"location":"workflow/variable_space/#adding-and-editing-variables","title":"Adding and Editing Variables","text":"<p>Each variable is represented as a row with the following fields:</p> <ul> <li>Variable Name: Enter a unique name for your variable.</li> <li>Type: Choose the variable type from the dropdown:</li> <li><code>Real</code>: For continuous variables (e.g., floating-point numbers).</li> <li><code>Integer</code>: For discrete variables (e.g., whole numbers).</li> <li><code>Categorical</code>: For variables with a set of named categories.</li> </ul> <p>Depending on the type selected: - Real/Integer: Enter minimum and maximum values in the <code>Min</code> and <code>Max</code> fields. - Categorical: Click Edit Values to open a dialog where you can enter possible category values (one per row). Click Save in the dialog to confirm.</p>"},{"location":"workflow/variable_space/#managing-variable-rows","title":"Managing Variable Rows","text":"<p>Use the buttons on the right panel to manage your variable list:</p> <ul> <li>Add Variable: Add a new variable row.</li> <li>Delete Row: Remove the currently selected variable.</li> <li>Clear Row: Clear all fields in the selected row.</li> <li>Move Up/Down: Change the order of variables by moving the selected row up or down.</li> </ul> <p>Click on a row to select it; the selected row is highlighted.</p>"},{"location":"workflow/variable_space/#saving-and-loading","title":"Saving and Loading","text":"<ul> <li>Save to File: Save your variable definitions to a <code>.json</code> or <code>.csv</code> file.</li> <li>Load from File: Load variable definitions from a <code>.json</code> or <code>.csv</code> file.</li> <li>Save &amp; Close: Save your current variable space and close the window. This also updates the application's internal search space.</li> </ul>"},{"location":"workflow/variable_space/#tips","title":"Tips","text":"<ul> <li>All fields must be filled out for a variable to be valid.</li> <li>For categorical variables, you must specify at least one value.</li> <li>You can reorder variables to control their order in the search space.</li> </ul>"},{"location":"workflow/variable_space/#example","title":"Example","text":"Variable Name Type Min Max Values temperature Real 20 100 batch_size Integer 1 10 catalyst Categorical A, B, C, D <p>For more details on how the variable space is used, see the rest of the workflow documentation.</p>"}]}